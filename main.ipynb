{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import argparse\n",
    "from string import punctuation\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from pypinyin import pinyin, Style\n",
    "\n",
    "from utils.model import get_model, get_vocoder\n",
    "from utils.tools import to_device, synth_samples\n",
    "from dataset import TextDataset\n",
    "from text import phoneme_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lexicon(lex_path):\n",
    "    lexicon = {}\n",
    "    with open(lex_path) as f:\n",
    "        for line in f:\n",
    "            temp = re.split(r\"\\s+\", line.strip(\"\\n\"))\n",
    "            word = temp[0]\n",
    "            phones = temp[1:]\n",
    "            if word.lower() not in lexicon:\n",
    "                lexicon[word.lower()] = phones\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"config/preprocess.yaml\"\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    preprocess_config = yaml.load(f,yaml.loader.SafeLoader)\n",
    "lexicon = read_lexicon(preprocess_config[\"path\"][\"lexicon_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"tôi tên là dương văn tuyển nhé\"\n",
    "\n",
    "text = text.lower()\n",
    "words = re.split(r\"([,;.\\-\\?\\!\\s+])\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes = []\n",
    "for word in words:\n",
    "    if word in lexicon:\n",
    "        phoneme = lexicon[word]\n",
    "        phonemes += phoneme\n",
    "    elif len(word.strip()) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        phonemes.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes = \"tɕ ɨə˦˥ k̚ x iː˨˨ l aː˨˨ m m oː˨˩ t̚ v iə˨˩ k̚ tʰ a˨˨ ɲ k o˨˨ ŋm h a˨ˀ˥ j k oː˨˦ tɕ əː˨˩˨ tʰ a˨˨ ɲ m oː˨˩ t̚ ŋ ɨə˨˨ j tʰ a˨˨ ɲ k o˨˨ ŋm\".split()\n",
    "# phonemes = \"ʔ a˨˥ n\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_ids = phoneme_to_ids(\" \".join(phonemes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_ids = np.array(phoneme_ids).reshape(1, len(phoneme_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_config = \"config/preprocess.yaml\"\n",
    "model_config = \"config/model.yaml\"\n",
    "train_config = \"config/train.yaml\"\n",
    "preprocess_config = yaml.load(open(preprocess_config, \"r\"), Loader=yaml.FullLoader)\n",
    "model_config = yaml.load(open(model_config, \"r\"), Loader=yaml.FullLoader)\n",
    "train_config = yaml.load(open(train_config, \"r\"), Loader=yaml.FullLoader)\n",
    "configs = (preprocess_config, model_config, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    restore_step = 76000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "_args = args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing weight norm...\n"
     ]
    }
   ],
   "source": [
    "model = get_model(_args, configs, device=\"cpu\", train=False)\n",
    "vocoder = get_vocoder(model_config, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lens = np.array([len(phoneme_ids[0])])\n",
    "ids = [text[0:100],]\n",
    "batch = [(\"test\", text, phoneme_ids, text_lens, max(text_lens))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(\n",
    "        texts = torch.tensor(phoneme_ids),\n",
    "        src_lens = torch.tensor(text_lens),\n",
    "        max_src_len = max(text_lens)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_samples(\n",
    "        batch,\n",
    "        output,\n",
    "        vocoder,\n",
    "        model_config,\n",
    "        preprocess_config,\n",
    "        train_config[\"path\"][\"result_path\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
